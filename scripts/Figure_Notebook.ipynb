{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import needed libraries\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "import sys\n",
    "import my_shell_tools\n",
    "\n",
    "# analysis\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "import itertools\n",
    "\n",
    "# geomip_data\n",
    "import os.path\n",
    "# import cf\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import all from projects python scripts\n",
    "\"\"\"\n",
    "\n",
    "from gfdl_data import *\n",
    "from get_glens_data import *\n",
    "from analysis import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHow much of this needed?\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "How much of this needed?\n",
    "\"\"\"\n",
    "\n",
    "# Directory and filenames for annual timeseries of 2D data\n",
    "glens_dir = '/n/home03/pjirvine/keithfs1_pji/GLENS/combined_annual_data/'\n",
    "glens_template = '{exp}.{run}.cam.h0.{var}.ann.{years}.nc'\n",
    "\n",
    "vars_glens = ['TREFHT','TREFHTMX','P-E','PRECTMX','PRECT']\n",
    "exps_glens = ['control','feedback']\n",
    "years = ['2010-2029','2075-2094']\n",
    "\n",
    "# year ranges which appears in filename\n",
    "control_file_years = '201001-209912'\n",
    "control_short_file_years = '201001-203012'\n",
    "feedback_file_years = '202001-209912'\n",
    "\n",
    "seas = 'ann'\n",
    "stats = ['mean','std']\n",
    "\n",
    "\"\"\"\n",
    "Specify years of experiments and associated indices for annual files\n",
    "\"\"\"\n",
    "\n",
    "years_control = np.array([IDX + 2010 for IDX in range(90)])\n",
    "years_feedback = np.array([IDX + 2020 for IDX in range(80)])\n",
    "\n",
    "#Generate the indices for the range of years in each case.\n",
    "# [0] added as a 2 element tuple with an array and an empty slot returned rather than an array\n",
    "t_index_control = np.where((years_control > 2074) & (years_control < 2095))[0]\n",
    "t_index_baseline = np.where((years_control > 2009) & (years_control < 2030))[0]\n",
    "t_index_feedback = np.where((years_feedback > 2074) & (years_feedback < 2095))[0]\n",
    "\n",
    "# Years when GLENS anom = half eventual cooling found using offline calculation with this function call: closest_years_to_frac_GLENS(0.5)\n",
    "t_index_feedback_half = np.where((years_feedback > 2043) & (years_feedback < 2064))[0]\n",
    "t_index_control_half = np.where((years_control > 2043) & (years_control < 2064))[0]\n",
    "\n",
    "\"\"\"\n",
    "How much of this needed?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMASKS:\\n'land_mask' - binary land mask where land fraction > 50%\\n'land_noice_mask' - binary land mask without Greenland or Antarctica and where land fraction > 50%\\nWEIGHTS:\\n'pop' - gridcell weighting by population fraction\\n'ag' - gridcell weighting by agricultural land fraction\\n'area' - simple gridcell weighting by area\\n'land_area' - land area weighting using raw land area fraction (not mask)\\n'land_noice_area' - land area without Greenland and Antarctica weighting using raw land area fraction (not mask)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate means and stds for all variables and cases\n",
    "\"\"\"\n",
    "\n",
    "# get lons, lats and weights\n",
    "lons, lats, weights = get_lons_lats_weights()\n",
    "\n",
    "# returnes (Means, Stds) for all cases and vars\n",
    "all_data = get_all_cases_vars() # {(var,case)}\n",
    "\"\"\"\n",
    "CASES:\n",
    "'Baseline'     - RCP8.5 @ 2010-2029\n",
    "'RCP8.5'       - RCP8.5 @ 2075-2094\n",
    "'Full-GLENS'   - GLENS  @ 2075-2094\n",
    "'Half-GLENS'   - Scaled Half-GLENS  @ 2075-2094\n",
    "'Baseline-2'   - RCP8.5 @ 2010-2029 W/ alternate runs\n",
    "'Full-GLENS-2'   - GLENS @ 2075-2094 W/ alternate runs\n",
    "'Half-GLENS-2'   - Scaled Half-GLENS @ 2075-2094 W/ alternate runs on GLENS (not on RCP8.5)\n",
    "### NOT DONE ### 'Half-GLENS-time' - Shifted Half-GLENS @ 2075-2094 AND ?????\n",
    "\"\"\"\n",
    "\n",
    "# get weights and masks\n",
    "all_masks = get_glens_masks_weights() # all_masks[masks]\n",
    "\"\"\"\n",
    "MASKS:\n",
    "'land_mask' - binary land mask where land fraction > 50%\n",
    "'land_noice_mask' - binary land mask without Greenland or Antarctica and where land fraction > 50%\n",
    "WEIGHTS:\n",
    "'pop' - gridcell weighting by population fraction\n",
    "'ag' - gridcell weighting by agricultural land fraction\n",
    "'area' - simple gridcell weighting by area\n",
    "'land_area' - land area weighting using raw land area fraction (not mask)\n",
    "'land_noice_area' - land area without Greenland and Antarctica weighting using raw land area fraction (not mask)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set standard plot options\n",
    "\"\"\"\n",
    "\n",
    "def cm2inch(*tupl):\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.rcParams.update({'figure.figsize': cm2inch(8.5,8.5)})\n",
    "\n",
    "# color guide here: https://www.w3schools.com/colors/colors_picker.asp\n",
    "# color blender here: https://meyerweb.com/eric/tools/color-blend\n",
    "red = '#ff0000'\n",
    "l_red = '#ffc0c0' # old: '#ffd9d9'\n",
    "blue = '#0066ff'\n",
    "l_blue = '#c0c0ff' # old:'#b2d0ff'\n",
    "purple = '#803380'\n",
    "l_purple = '#C099C0' \n",
    "\n",
    "std_alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300 # set inline images to hi-res\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERT FIGURE SECTIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load figure_sections/srex_region_maps.py\n",
    "\n",
    "\"\"\"\n",
    "Set mask directories and names\n",
    "\"\"\"\n",
    "\n",
    "SREX_abvs = ['ALA', 'CGI', 'WNA', 'CNA', 'ENA', 'CAM', 'AMZ', 'NEB', 'WSA', 'SSA', 'NEU', 'CEU', 'MED', 'SAH', 'WAF', 'EAF', 'SAF', 'NAS', 'WAS', 'CAS', 'TIB', 'EAS', 'SAS', 'SEA', 'NAU', 'SAU']\n",
    "SREX_names = ['Alaska', 'Canada and Greenland', 'Western North America', 'Central North America', 'Eastern North America', 'Central America', 'Amazon', 'North Eastern Brazil', 'Western South America', 'Southern South America', 'Northern Europe', 'Central Europe', 'Mediterannean', 'Sahara', 'Western Africa', 'Eastern Africa', 'Southern Africa', 'Northern Asia', 'Western Asia', 'Central Asia', 'Tibet', 'Eastern Asia', 'Southern Asia', 'South Eastern Asia', 'Northern Australia', 'Southern Australia']\n",
    "\n",
    "\n",
    "# This function gets the region masks from the file, masks them and reshapes them \n",
    "# to match the data_shape given.\n",
    "\n",
    "def get_regions_for_mean(region_fileloc, region_name_list, data_shape, mask=None):\n",
    "    \"\"\"\n",
    "    This function gets the region masks from the file, masks them and reshapes them \n",
    "    to match the data_shape given.\n",
    "    \"\"\"\n",
    "    \n",
    "    # This Sub-function normalizes the input mask\n",
    "    def region_mask_norm(region_data, mask=None):\n",
    "        # change from % to fraction\n",
    "        region_1 = np.copy(region_data) / 100.\n",
    "        # apply mask if present\n",
    "        if mask is None:\n",
    "            pass\n",
    "        else:\n",
    "            region_1 = region_1 * mask\n",
    "        # normalize region\n",
    "        return region_1 / np.sum(region_1)\n",
    "    # End DEF\n",
    "    \n",
    "    # load region data\n",
    "    region_nc = Dataset(region_fileloc)\n",
    "    # make list of mask data for regions\n",
    "    region_nc_data_list = [ region_nc.variables[ X ][:] for X in region_name_list]\n",
    "    # Normalize region mask data\n",
    "    region_data_n_list = [ region_mask_norm( X, mask=mask ) for X in region_nc_data_list]\n",
    "    # Expand mask along time dimension to have same shape as data_nc_data\n",
    "    region_data_exp_list = [ np.repeat(X, data_shape[0], axis=0) for X in region_data_n_list]\n",
    "    \n",
    "    return region_data_exp_list\n",
    "#END DEF: get_regions_for_mean(region_fileloc, region_name_list, data_shape, mask=None)\n",
    "\n",
    "def regional_means_stds(var, case):\n",
    "    \"\"\"\n",
    "    This function calculates regional-mean timeseries over the SREX regions\n",
    "    \"\"\"\n",
    "    \n",
    "    data = ensemble_process(var,case, timeseries=True)[0] # [0] to select means\n",
    "\n",
    "    # transpose data to match form of region mask data\n",
    "    data = np.transpose(data)\n",
    "\n",
    "    region_dir = '/n/home03/pjirvine/projects/datasets_regions/SREX_Giorgi/geomip_masks/'\n",
    "    region_file = 'CCSM4_SREX_sep.nc'\n",
    "    \n",
    "    region_fileloc = region_dir + region_file\n",
    "    region_data_list = get_regions_for_mean(region_fileloc, SREX_abvs, np.shape(data), mask=all_masks['land_mask'])\n",
    "\n",
    "    # weighted (S)patial mean of regions (over time):\n",
    "    region_mean_s_list = [ np.sum(data * X, axis=(1,2)) for X in region_data_list ]\n",
    "\n",
    "    #calculate mean and standard deviation over time.\n",
    "    region_time_mean_list = [ np.mean(X) for X in region_mean_s_list ]\n",
    "    region_time_std_list = [ np.std(X) for X in region_mean_s_list ]\n",
    "\n",
    "    # Store mean and standard deviation in dict, with regions as \"rows\"\n",
    "    mean_dict = dict(zip(SREX_abvs,region_time_mean_list))\n",
    "    std_dict = dict(zip(SREX_abvs,region_time_std_list))\n",
    "    \n",
    "    return mean_dict, std_dict\n",
    "#end def: regional_means_stds(var, case)\n",
    "\n",
    "def make_plot_data(var, regional_data_dict, anom_type='units', ttest_level=0.1, nyears=20):\n",
    "    \"\"\"\n",
    "    ttest_level: 0.1 = 90%, nyears: 20 as ensemble mean for each year calculated, which reduces stddev\n",
    "    \"\"\"\n",
    "    \n",
    "    def num_stds_ttest(nobs, ttest_level, num=1000):\n",
    "        import numpy as np\n",
    "        from scipy.stats import ttest_ind_from_stats\n",
    "        \"\"\"\n",
    "        reports number of stds to pass a t-test of a given level for a certain number of years\n",
    "        ttest_level: 0.1 = 90%, 0.05 = 95%\n",
    "        \"\"\"\n",
    "\n",
    "        xfactor = 1. / num\n",
    "\n",
    "        results = np.array([ttest_ind_from_stats(X * xfactor, 1, nobs, 0, 1, nobs)[1] for X in range(num)])\n",
    "        num_stds = np.array([X * xfactor for X in range(num)])\n",
    "\n",
    "        # return number of STDs for T-Test\n",
    "        return min( num_stds [ results < ttest_level ])\n",
    "    \n",
    "    SREX_abvs = ['ALA', 'CGI', 'WNA', 'CNA', 'ENA', 'CAM', 'AMZ', 'NEB', 'WSA', 'SSA', 'NEU', 'CEU', 'MED', 'SAH', 'WAF', 'EAF', 'SAF', 'NAS', 'WAS', 'CAS', 'TIB', 'EAS', 'SAS', 'SEA', 'NAU', 'SAU']\n",
    "    SREX_names = ['Alaska', 'Canada and Greenland', 'Western North America', 'Central North America', 'Eastern North America', 'Central America', 'Amazon', 'North Eastern Brazil', 'Western South America', 'Southern South America', 'Northern Europe', 'Central Europe', 'Mediterannean', 'Sahara', 'Western Africa', 'Eastern Africa', 'Southern Africa', 'Northern Asia', 'Western Asia', 'Central Asia', 'Tibet', 'Eastern Asia', 'Southern Asia', 'South Eastern Asia', 'Northern Australia', 'Southern Australia']\n",
    "    SREX_region_centres = [[-136.511,   66.277],[-57.5,  67.5],[-117.5  ,   44.283],[-95.   ,  39.283],[-72.5,  37.5],[-90.25802898,  16.60289305],[-62.05181777,  -3.75447446],[-42., -10.],[-75.89741775, -30.77603057],[-54.40601015, -38.77303345],[12.27138643, 64.46654867],[20.74534161, 50.5952795 ],[15. , 37.5],[10. , 22.5],[2.5   , 1.8175],[38.495 ,  1.8175],[ 20.995 , -23.1825],[110.,  60.],[50. , 32.5],[67.5, 40. ],[87.5, 40. ],[122.5,  35. ],[78.58108108, 17.90540541],[125.,   5.],[132.5, -20. ],[145., -40.]]\n",
    "    \n",
    "    # dictionary to hold plot data for each region\n",
    "    SREX_plot_dict = {}\n",
    "    for SREX in SREX_abvs:\n",
    "        \n",
    "        plot_dict = {} # temporary plot data dict\n",
    "        \n",
    "        plot_dict['name'] = SREX_names[SREX_abvs.index(SREX)] # use index from SREX_Abvs list to find matching entries\n",
    "        plot_dict['centre'] = SREX_region_centres[SREX_abvs.index(SREX)]\n",
    "        plot_dict['displace'] = [0,0] # these will be edited later\n",
    "        \n",
    "        # calculate number of STDs from control for 90% T-Test:\n",
    "        num_ctrl_stds = num_stds_ttest(nyears, ttest_level)\n",
    "        \n",
    "        if anom_type == 'units':\n",
    "            plot_dict['anom_85'] = regional_data_dict[var]['RCP8.5'][0][SREX] - regional_data_dict[var]['Baseline'][0][SREX]\n",
    "            plot_dict['anom_GLENS'] = regional_data_dict[var]['Full-GLENS'][0][SREX] - regional_data_dict[var]['Baseline'][0][SREX]\n",
    "            plot_dict['ttest_ctrl'] = num_ctrl_stds * regional_data_dict[var]['Baseline'][1][SREX]\n",
    "        elif anom_type == 'pc':\n",
    "            plot_dict['anom_85'] = 100. * ((regional_data_dict[var]['RCP8.5'][0][SREX] / regional_data_dict[var]['Baseline'][0][SREX]) - 1.0)\n",
    "            plot_dict['anom_GLENS'] = 100. * ((regional_data_dict[var]['Full-GLENS'][0][SREX] / regional_data_dict[var]['Baseline'][0][SREX]) - 1.0)\n",
    "            plot_dict['ttest_ctrl'] = 100. * ((num_ctrl_stds * regional_data_dict[var]['Baseline'][1][SREX]) / regional_data_dict[var]['Baseline'][0][SREX])\n",
    "        elif anom_type == 'sd':\n",
    "            plot_dict['anom_85'] = (regional_data_dict[var]['RCP8.5'][0][SREX] - regional_data_dict[var]['Baseline'][0][SREX]) / regional_data_dict[var]['Baseline'][1][SREX]\n",
    "            plot_dict['anom_GLENS'] = (regional_data_dict[var]['Full-GLENS'][0][SREX] - regional_data_dict[var]['Baseline'][0][SREX]) / regional_data_dict[var]['Baseline'][1][SREX]\n",
    "            plot_dict['ttest_ctrl'] = num_ctrl_stds\n",
    "        else:\n",
    "            print(\"anom_type not recognized: \", anom_type,\" please input: units, pc or sd\")\n",
    "            return\n",
    "        \n",
    "        # check whether RCP8.5 and GLENS are significantly different:\n",
    "        ttest_plevel = ttest_sub(regional_data_dict[var]['RCP8.5'][0][SREX], regional_data_dict[var]['RCP8.5'][1][SREX], nyears, regional_data_dict[var]['Full-GLENS'][0][SREX], regional_data_dict[var]['Full-GLENS'][1][SREX], nyears)\n",
    "        plot_dict['ttest_anoms'] = ttest_plevel < ttest_level\n",
    "        \n",
    "        def num_format(num, anom_type):\n",
    "            string = f'{num:.2f}'\n",
    "            if num > 0:\n",
    "                string = \"+\"+string\n",
    "            if anom_type == 'pc':\n",
    "                string = string + '%'\n",
    "            return string\n",
    "                   \n",
    "        plot_dict['anom_85_text'] = num_format(plot_dict['anom_85'],anom_type)\n",
    "        plot_dict['anom_GLENS_text'] = num_format(plot_dict['anom_GLENS'],anom_type)\n",
    "        \n",
    "        SREX_plot_dict[SREX] = plot_dict\n",
    "    # end for SREX_abvs\n",
    "                   \n",
    "    return SREX_plot_dict\n",
    "#end def make_plot_data()\n",
    "\n",
    "\"\"\"\n",
    "Create nested dictionary with regional means and stds.\n",
    "To access data:\n",
    "regional_data_dict[var][case][0/1][SREX_ABV]\n",
    "[0] for mean, [1] for std\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Create regional_data_dict\n",
    "\"\"\"\n",
    "case_list = ['Baseline','RCP8.5','Full-GLENS','Half-GLENS']\n",
    "\n",
    "var_dict = {} # create dict to store loops output\n",
    "for var in vars_glens:\n",
    "    case_dict = {} # create dict to store loops output\n",
    "    for case in case_list:\n",
    "        case_dict[case] = regional_means_stds(var, case)\n",
    "    var_dict[var] = case_dict\n",
    "\n",
    "# Rename var_dict\n",
    "regional_data_dict = var_dict\n",
    "\n",
    "\"\"\"\n",
    "Make data for each variable plot\n",
    "\"\"\"\n",
    "\n",
    "TREFHT_regions = make_plot_data('TREFHT', regional_data_dict, anom_type='units')\n",
    "TREFHTMX_regions = make_plot_data('TREFHTMX', regional_data_dict, anom_type='units')\n",
    "PRECTMX_regions = make_plot_data('PRECTMX', regional_data_dict, anom_type='units')\n",
    "PRECT_regions = make_plot_data('PRECT', regional_data_dict, anom_type='units')\n",
    "PE_regions = make_plot_data('P-E', regional_data_dict, anom_type='units')\n",
    "\n",
    "\"\"\"\n",
    "Specify Common plot_Region_dict updates\n",
    "\"\"\"\n",
    "\n",
    "displace_dict = {'CAM': [-5.0,-5.0],\n",
    "                 'NEB': [5.0,2.0],\n",
    "                 'ENA': [5.0,-5.0],\n",
    "                 'WSA': [-8.,2.],\n",
    "                 'WAF': [0.0,-5.0],\n",
    "                 'SAF': [5.0,-10.0],\n",
    "                 'SAH': [-8.0,0.0],\n",
    "                 'MED': [8.0,-2.],\n",
    "                 'CEU': [10.,20.0],\n",
    "                 'NEU': [-8.,5.],\n",
    "                 'CAS': [5.0,25.0],\n",
    "                 'SAS': [0.0, -5.0],\n",
    "                 'SAU': [10.,-5.],\n",
    "                }\n",
    "\n",
    "def plot_srex_region_map(var_regions,out_loc):\n",
    "    \"\"\"\n",
    "    Function to plot srex region map\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import\n",
    "    import regionmask\n",
    "    import cartopy.crs as ccrs\n",
    "    \n",
    "    # plot updates\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    plt.rcParams.update({'figure.figsize': (18,9)}) # Square panels (2 across a page)\n",
    "    \n",
    "    def mini_panels(axis, plot_dict, half_width = 8):\n",
    "\n",
    "        # extract values from plot_dict\n",
    "        anom_1 = plot_dict['anom_85']\n",
    "        anom_2 = plot_dict['anom_GLENS']\n",
    "        ttest_anom = plot_dict['ttest_ctrl']\n",
    "        x_loc, y_loc = plot_dict['centre']\n",
    "        displace_x, displace_y = plot_dict['displace']\n",
    "        text_1 = plot_dict['anom_85_text']\n",
    "        text_2 = plot_dict['anom_GLENS_text']\n",
    "\n",
    "        \"\"\"\n",
    "        Displace origin if needed and plot line\n",
    "        \"\"\"\n",
    "        if plot_dict['displace'] != [0,0]:\n",
    "\n",
    "            x_loc_orig, y_loc_orig = x_loc, y_loc\n",
    "\n",
    "            x_loc = x_loc + displace_x\n",
    "            y_loc = y_loc + displace_y\n",
    "\n",
    "            axis.plot([x_loc,x_loc_orig],[y_loc,y_loc_orig],'k',linewidth=3, zorder=2)\n",
    "\n",
    "        \"\"\"\n",
    "        Normalize anomalies for plotting\n",
    "        \"\"\"\n",
    "        big_anom = max(abs(anom_1),abs(anom_2))\n",
    "        norm_value = max(big_anom,abs(2.*ttest_anom))\n",
    "\n",
    "        norm_anom_1 = anom_1 / norm_value\n",
    "        norm_anom_2 = anom_2 / norm_value\n",
    "        norm_ttest_anom = ttest_anom / norm_value\n",
    "\n",
    "        # Set some plotting standards\n",
    "        thick = 0.3\n",
    "        bar_loc = 0.6\n",
    "\n",
    "        \"\"\"\n",
    "        Create the background and anomalies\n",
    "        \"\"\"\n",
    "        patches = [\n",
    "            # Black Border for Background\n",
    "            mpatches.Rectangle((x_loc - 1.05*half_width,y_loc - 1.15*half_width), 2.1*half_width, 2.6*half_width, facecolor='k', linewidth=0, zorder=3),\n",
    "            # White Background\n",
    "            mpatches.Rectangle((x_loc - half_width,y_loc - 1.1*half_width), 2*half_width, 2.5*half_width, facecolor='white', linewidth=0, zorder=3),\n",
    "            # Ttest grey bar\n",
    "            mpatches.Rectangle((x_loc - half_width,y_loc - norm_ttest_anom * half_width), 2*half_width, 2.* norm_ttest_anom * half_width, facecolor='gray', linewidth=0, zorder=3),\n",
    "            # Anom_1\n",
    "            mpatches.Rectangle((x_loc - (bar_loc + 0.5*thick) * half_width,y_loc), thick*half_width, norm_anom_1 * half_width, facecolor='r', linewidth=0, zorder=4),\n",
    "            # Anom_2\n",
    "            mpatches.Rectangle((x_loc + (bar_loc - 0.5*thick) * half_width,y_loc), thick*half_width, norm_anom_2 * half_width, facecolor='b', linewidth=0, zorder=4),        \n",
    "        ]\n",
    "        for p in patches:\n",
    "            axis.add_patch(p)\n",
    "\n",
    "        \"\"\"\n",
    "        Add the lines\n",
    "        \"\"\"\n",
    "        #zero line\n",
    "        axis.plot([x_loc - half_width,x_loc + half_width],[y_loc,y_loc],'k',linewidth=1, zorder=5)\n",
    "\n",
    "        #Between line\n",
    "        axis.plot([x_loc - (bar_loc * half_width), x_loc + (bar_loc * half_width)],[y_loc + (norm_anom_1 * half_width),y_loc + (norm_anom_2 * half_width)],'k',linewidth=1, zorder=3)\n",
    "\n",
    "        #Half-way Point\n",
    "        axis.plot([x_loc],[y_loc + 0.5 * (norm_anom_1 + norm_anom_2) * half_width],color='purple', marker='.', markersize=12, zorder=4)\n",
    "\n",
    "        \"\"\"\n",
    "        Add the text values\n",
    "        \"\"\"\n",
    "        #text\n",
    "        axis.text(x_loc - bar_loc * half_width, y_loc + 1.05*half_width, text_1,  horizontalalignment='center', verticalalignment='bottom', fontsize=8, zorder=4)\n",
    "        axis.text(x_loc + bar_loc * half_width, y_loc + 1.05*half_width, text_2,  horizontalalignment='center', verticalalignment='bottom', fontsize=8, zorder=4)\n",
    "        ### FIN ###\n",
    "    #end def mini_panels()\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply common updates to plot_dict\n",
    "    \"\"\"\n",
    "    # Function to update plot_regions_dict\n",
    "    def update_plot_regions(plot_regions_dict, plot_value, update_dict):\n",
    "        for SREX, update_value in update_dict.items():\n",
    "            plot_regions_dict[SREX][plot_value] = update_value\n",
    "    #end def\n",
    "    \n",
    "    update_plot_regions(var_regions,'displace', displace_dict)\n",
    "\n",
    "    \"\"\"\n",
    "    Create SREX mask used as base for summary plot\n",
    "    \"\"\"\n",
    "    ax = regionmask.defined_regions.srex.plot(add_label=False, line_kws={'zorder':1, 'linewidth':1})\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \"\"\"\n",
    "    Plot mini-panels for each SREX region\n",
    "    \"\"\"\n",
    "    for SREX in SREX_abvs:\n",
    "        mini_panels(ax, var_regions[SREX])\n",
    "\n",
    "    \"\"\"\n",
    "    Save Figure\n",
    "    \"\"\"    \n",
    "    plt.savefig(out_loc+'.eps', format='eps', dpi=480)\n",
    "    plt.savefig(out_loc+'.png', format='png', dpi=480)\n",
    "    plt.show()\n",
    "# end def\n",
    "\n",
    "\"\"\"\n",
    "Actually Make the Plots!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "out_dir = '/n/home03/pjirvine/projects/GLENS_fraction_better_off/figures/'\n",
    "\n",
    "# Plot T\n",
    "plot_srex_region_map(TREFHT_regions,out_dir + 'TREFHT_SREX_region_map')\n",
    "\n",
    "# Plot Tmax\n",
    "plot_srex_region_map(TREFHTMX_regions,out_dir + 'TREFHTMX_SREX_region_map')\n",
    "\n",
    "# Plot P\n",
    "plot_srex_region_map(PRECT_regions,out_dir + 'PRECT_SREX_region_map')\n",
    "\n",
    "# Plot Pmax\n",
    "plot_srex_region_map(PRECTMX_regions,out_dir + 'PRECTMX_SREX_region_map')\n",
    "\n",
    "# Plot P-E\n",
    "plot_srex_region_map(PE_regions,out_dir + 'P-E_SREX_region_map')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Example NetCDF to see contents and map results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example netcdf file of annual series + gather lons and lats\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "variables(dimensions): float64 time(time), float64 time_bnds(time,bnds), \n",
    "    float64 lat(lat), float64 lon(lon), float64 gw(lat), float64 ch4vmr(time), \n",
    "    float64 co2vmr(time), int32 ndcur(time), int32 date(time), int32 nscur(time), \n",
    "    float64 sol_tsi(time), int32 nsteph(time), float64 f11vmr(time), float64 n2ovmr(time), \n",
    "    int32 datesec(time), float64 f12vmr(time), float32 TREFHT(time,lat,lon)\n",
    "\"\"\"\n",
    "\n",
    "var='TREFHT'\n",
    "exp='control'\n",
    "run='001'\n",
    "file_years='201001-209912'\n",
    "\n",
    "glens_dir = '/n/home03/pjirvine/keithfs1_pji/GLENS/combined_annual_data/'\n",
    "glens_filename = '{exp}.{run}.cam.h0.{var}.ann.{years}.nc'.format(exp=exp,run=run,var=var,years=file_years)\n",
    "\n",
    "glens_fileloc = glens_dir + glens_filename\n",
    "test_nc = Dataset(glens_fileloc)\n",
    "\n",
    "lons = np.array(test_nc.variables['lon'][:])\n",
    "lats = np.array(test_nc.variables['lat'][:])\n",
    "\n",
    "# grid-weights by latitude\n",
    "gw = test_nc.variables['gw'][:]\n",
    "gw_2D = np.tile(gw, (lons.size,1))\n",
    "gw_2D = gw_2D / np.sum(gw_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get example netcdf\n",
    "# glens_dir = '/n/home03/pjirvine/keithfs1_pji/GLENS/combined_annual_data/'\n",
    "# glens_filename = 'control.001.cam.h0.TREFHT.ann.201001-209912.nc'\n",
    "# glens_fileloc = glens_dir + glens_filename\n",
    "# test_nc = Dataset(glens_fileloc)\n",
    "\n",
    "fix_dir = '/n/home03/pjirvine/keithfs1_pji/geomip_archive/final_data/CCSM4/fix/'\n",
    "filename = 'sftlf_CCSM4.nc'\n",
    "test_nc = Dataset(fix_dir + filename)\n",
    "\n",
    "nc_data = test_nc.variables['sftlf'][:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    MASKS:\n",
    "    'land_mask' - binary land mask where land fraction > 50%\n",
    "    'land_noice_mask' - binary land mask without Greenland or Antarctica and where land fraction > 50%\n",
    "    WEIGHTS:\n",
    "    'pop' - gridcell weighting by population fraction\n",
    "    'ag' - gridcell weighting by agricultural land fraction\n",
    "    'area' - simple gridcell weighting by area\n",
    "    'land_area' - land area weighting using raw land area fraction (not mask)\n",
    "    'land_noice_area' - land area without Greenland and Antarctica weighting using raw land area fraction (not mask)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example cartopy plot\n",
    "\n",
    "http://earthpy.org/tag/cartopy.html\n",
    "https://scitools.org.uk/cartopy/docs/v0.16/matplotlib/advanced_plotting.html\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "# #Get example netcdf\n",
    "# glens_dir = '/n/home03/pjirvine/keithfs1_pji/GLENS/combined_annual_data/'\n",
    "# glens_filename = 'control.001.cam.h0.TREFHT.ann.201001-209912.nc'\n",
    "# glens_fileloc = glens_dir + glens_filename\n",
    "# test_nc = Dataset(glens_fileloc)\n",
    "\n",
    "# nc_data = test_nc.variables['TREFHT'][:].transpose()\n",
    "# data = np.mean(nc_data,2)\n",
    "\n",
    "# data = all_masks['land_noice_mask'].transpose()\n",
    "\n",
    "data = all_data[('P-E','Baseline')][0]\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# plt.figure(figsize=(13,6.2))  \n",
    "# ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "lons2d, lats2d = np.meshgrid(lons, lats)\n",
    "\n",
    "plt.contourf(lons2d, lats2d, data.transpose(), 60,\n",
    "             transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "\n",
    "# fig.colorbar(cm.ScalarMappable(),ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_data[('P-E','RCP8.5')][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:climate_odyssey]",
   "language": "python",
   "name": "conda-env-climate_odyssey-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
